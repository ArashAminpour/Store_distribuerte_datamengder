{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "track_df = pd.read_csv(\"trajectory.csv\")\n",
    "\n",
    "track_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformations and fixing types of columns \n",
    "\n",
    "track_df['user'] = track_df['user'].astype(str).str.zfill(3)\n",
    "track_df[\"activity\"] = track_df['activity'].astype(str)\n",
    "track_df[\"time_string\"] = track_df[\"time_string\"].str.replace('\\n', '')\n",
    "track_df[\"date_time\"] = track_df[\"date_string\"] + \" \" + track_df[\"time_string\"]\n",
    "track_df['date_time'] = pd.to_datetime(track_df['date_time'], format='%Y-%m-%d %H:%M:%S')\n",
    "track_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Go back one directory level\n",
    "parent_directory = os.path.abspath(os.path.join(current_directory, '..','..'))\n",
    "\n",
    "# Construct the relative paths\n",
    "data_path = os.path.join(parent_directory, 'dataset')\n",
    "data_path2 = os.path.join(parent_directory, 'dataset', 'Data')\n",
    "\n",
    "print(data_path)\n",
    "print(data_path2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get all user_id and check if they have label\n",
    "\n",
    "def get_user_id(data_path): \n",
    "    directories_data = os.listdir(f'{data_path}/Data')\n",
    "    labeled_ids_path = f'{data_path}/labeled_ids.txt'\n",
    "    \n",
    "    with open(labeled_ids_path, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "    ids = [line.strip().split()[0] for line in lines]\n",
    "\n",
    "    df= pd.DataFrame({\"id\": directories_data})\n",
    "    labeled_ids_df = pd.DataFrame({\"LabelID\":ids})\n",
    "\n",
    "    merged_df = pd.merge(df, labeled_ids_df, left_on=\"id\", right_on=\"LabelID\", how = \"left\")\n",
    "    merged_df[\"has_labels\"] = merged_df[\"LabelID\"].notna()\n",
    "    merged_df.drop(\"LabelID\", axis=1, inplace=True)\n",
    "\n",
    "    return merged_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_user_id(data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking if all trajectories is unique for each user\n",
    "\n",
    "# Initializing a dictionary to store the lists\n",
    "lists_by_directory = {}\n",
    "\n",
    "for i in range(182): \n",
    "    directory_name = f\"{i:03d}\"  # Format the directory name to have leading zeros if needed\n",
    "\n",
    "   \n",
    "    files_in_directory = os.listdir(os.path.join(data_path2, directory_name, \"Trajectory\"))\n",
    "\n",
    "    lists_by_directory[directory_name] = files_in_directory\n",
    "    \n",
    "\n",
    "# Check if all values in each list are unique\n",
    "for directory_name, file_list in lists_by_directory.items():\n",
    "    is_unique = len(file_list) == len(set(file_list))\n",
    "    print(f\"Directory {directory_name}:Values are not unique - {is_unique}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for getting the content in labels.txt for those user which have has_label = True\n",
    "def get_labels(path): \n",
    "    labels_df = labels_df = pd.DataFrame(columns=[\"User\",\"Start_time\", \"End_time\", \"Transportation_mode\"])\n",
    "    user_df = get_user_id(data_path)\n",
    "    folders_with_labels = user_df[user_df[\"has_labels\"]]\n",
    "    \n",
    "    for index, row in folders_with_labels.iterrows(): \n",
    "        folder_id = row[\"id\"]\n",
    "    \n",
    "        labels_file_path = os.path.join(path, folder_id, \"labels.txt\").replace(\"\\\\\", \"/\")\n",
    "        \n",
    "\n",
    "        if os.path.isfile(labels_file_path): \n",
    "            labels_data = pd.read_csv(labels_file_path, sep = \"\\t\", names=['Start_time', 'End_time', 'Transportation_mode'])\n",
    "            labels_data[\"User\"] = folder_id\n",
    "            labels_df = pd.concat([labels_df, labels_data], ignore_index=True)\n",
    "            return_df = labels_df.iloc[1:]\n",
    "\n",
    "    return return_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = get_labels(data_path2)\n",
    "label_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Findig those rows which have invalid format on start/end time \n",
    "\n",
    "incorrect_start_times = []\n",
    "incorrect_end_times = []\n",
    "\n",
    "for index, row in label_df.iterrows():\n",
    "    try:\n",
    "        pd.to_datetime(row['Start_time'], format=\"%Y/%m/%d %H:%M:%S\")\n",
    "    except ValueError:\n",
    "        incorrect_start_times.append(index)\n",
    "\n",
    "    try:\n",
    "            pd.to_datetime(row['End_time'], format=\"%Y/%m/%d %H:%M:%S\")\n",
    "    except ValueError:\n",
    "            incorrect_end_times.append(index)\n",
    "\n",
    "print(incorrect_start_times)\n",
    "print(incorrect_end_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the rows that had wrong format\n",
    "mask = label_df.index.isin(incorrect_start_times)\n",
    "wrong_df = label_df[mask]\n",
    "wrong_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Formating from string to datetime object so comparisons can be made. Those invalid rows have NaT (Not a Time)\n",
    "label_df['Start_time'] = pd.to_datetime(label_df['Start_time'], format=\"%Y/%m/%d %H:%M:%S\", errors='coerce')\n",
    "label_df['End_time'] = pd.to_datetime(label_df['End_time'], format=\"%Y/%m/%d %H:%M:%S\", errors='coerce')\n",
    "label_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for duplicates in user, start_time and end_time\n",
    "label_df.duplicated(subset=['User', 'Start_time', 'End_time']).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_df = pd.DataFrame(columns=[\"id\",\"User\", \"transportation_mode\", \"start_date_time\", \"end_date_time\"])\n",
    "activity_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_start_end(track_df):\n",
    "    # Group the track data by 'user' and 'activity'\n",
    "    grouped = track_df.groupby(['user', 'activity'])\n",
    "\n",
    "    # Initialize empty lists to store results\n",
    "    users = []\n",
    "    activities = []\n",
    "    start_times = []\n",
    "    end_times = []\n",
    "\n",
    "    # Iterate through each group\n",
    "    for (user, activity), group_df in grouped:\n",
    "        # Find the earliest and latest datetime for the user and activity\n",
    "        earliest_time = group_df['date_time'].min()\n",
    "        latest_time = group_df['date_time'].max()\n",
    "\n",
    "        # Append the results to the lists\n",
    "        users.append(user)\n",
    "        activities.append(activity)\n",
    "        start_times.append(earliest_time)\n",
    "        end_times.append(latest_time)\n",
    "\n",
    "    # Create a new DataFrame to store the results\n",
    "    result_df = pd.DataFrame({\n",
    "        'User': users,\n",
    "        'Activity': activities,\n",
    "        'Start_time': start_times,\n",
    "        'End_time': end_times\n",
    "    })\n",
    "\n",
    "    return result_df\n",
    "\n",
    "start_end_df = find_start_end(track_df)\n",
    "start_end_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df\n",
    "\n",
    "#check for duplicates in label_df of user, start_time and end_time\n",
    "label_df.duplicated(subset=['User', 'Start_time', 'End_time']).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge label_df and start_end_df and use nan where Transportation_mode is not available\n",
    "merged_df = pd.merge(start_end_df, label_df, on=[\"User\", \"Start_time\", \"End_time\"], how=\"outer\")\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df\n",
    "#droping rows with nan values in activity\n",
    "merged_df.dropna(subset = [\"Activity\"], inplace=True)\n",
    "merged_df\n",
    "\n",
    "activity_df = merged_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_transport = merged_df[merged_df[\"Transportation_mode\"].notna()]\n",
    "with_transport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
